{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display  # Added for spectrogram visualization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c24c0f",
   "metadata": {},
   "source": [
    "The dataset was automatically get splited as Training and  Testing dataset as 20% from  environment_audio and gunshots_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SETTINGS ==========\n",
    "DATASET_PATH = r\"dataset\"  # Path to the dataset directory\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 2\n",
    "SAMPLES_PER_CLIP = SAMPLE_RATE * DURATION\n",
    "MAX_PAD_LEN = 44\n",
    "\n",
    "# ========== DATASET SIZE CONTROL ==========\n",
    "# Set to None to use all available files, or specify a number to limit the dataset size\n",
    "NUM_ENVIRONMENT_FILES = NUM_GUNSHOT_FILES = 2000 # Using smaller dataset for demo/export\n",
    "\n",
    "print(f\"Dataset Configuration:\")\n",
    "print(f\"Environment files to use: {NUM_ENVIRONMENT_FILES if NUM_ENVIRONMENT_FILES else 'ALL'}\")\n",
    "print(f\"Gunshot files to use: {NUM_GUNSHOT_FILES if NUM_GUNSHOT_FILES else 'ALL'}\")\n",
    "print(f\"Sample rate: {SAMPLE_RATE} Hz\")\n",
    "print(f\"Audio duration: {DURATION} seconds\")\n",
    "print(f\"MFCC features: 13 coefficients x {MAX_PAD_LEN} time frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CHECK AVAILABLE FILES ==========\n",
    "def check_available_files():\n",
    "    env_path = os.path.join(DATASET_PATH, \"environment_audio\")\n",
    "    gun_path = os.path.join(DATASET_PATH, \"gunshots_audio\")\n",
    "    \n",
    "    env_files = [f for f in os.listdir(env_path) if f.endswith(\".wav\")]\n",
    "    gun_files = [f for f in os.listdir(gun_path) if f.endswith(\".wav\")]\n",
    "    \n",
    "    print(\" Available Audio Files:\")\n",
    "    print(f\"   Environment files: {len(env_files)}\")\n",
    "    print(f\"   Gunshot files: {len(gun_files)}\")\n",
    "    print(f\"   Total available: {len(env_files) + len(gun_files)}\")\n",
    "\n",
    "    return len(env_files), len(gun_files)\n",
    "\n",
    "# Run the check\n",
    "available_env, available_gun = check_available_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FEATURE EXTRACTION ==========\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        if len(audio) < SAMPLES_PER_CLIP:\n",
    "            audio = np.pad(audio, (0, SAMPLES_PER_CLIP - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:SAMPLES_PER_CLIP]\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        if mfccs.shape[1] < MAX_PAD_LEN:\n",
    "            pad_width = MAX_PAD_LEN - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfccs = mfccs[:, :MAX_PAD_LEN]\n",
    "        return mfccs.T  # shape (44, 13)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== LOAD DATA ==========\n",
    "def load_and_extract():\n",
    "    X_env, X_gun = [], []\n",
    "    \n",
    "    # Get environment audio files\n",
    "    env_files = [f for f in os.listdir(os.path.join(DATASET_PATH, \"environment_audio\")) if f.endswith(\".wav\")]\n",
    "    if NUM_ENVIRONMENT_FILES is not None:\n",
    "        env_files = env_files[:NUM_ENVIRONMENT_FILES]\n",
    "    \n",
    "    print(f\"Processing {len(env_files)} environment audio files...\")\n",
    "    for i, file in enumerate(env_files):\n",
    "        f = extract_features(os.path.join(DATASET_PATH, \"environment_audio\", file))\n",
    "        if f is not None:\n",
    "            X_env.append(f)\n",
    "        if (i + 1) % 50 == 0:  # Progress indicator\n",
    "            print(f\"  Processed {i + 1}/{len(env_files)} environment files\")\n",
    "    \n",
    "    # Get gunshot audio files\n",
    "    gun_files = [f for f in os.listdir(os.path.join(DATASET_PATH, \"gunshots_audio\")) if f.endswith(\".wav\")]\n",
    "    if NUM_GUNSHOT_FILES is not None:\n",
    "        gun_files = gun_files[:NUM_GUNSHOT_FILES]\n",
    "    \n",
    "    print(f\"Processing {len(gun_files)} gunshot audio files...\")\n",
    "    for i, file in enumerate(gun_files):\n",
    "        f = extract_features(os.path.join(DATASET_PATH, \"gunshots_audio\", file))\n",
    "        if f is not None:\n",
    "            X_gun.append(f)\n",
    "        if (i + 1) % 50 == 0:  # Progress indicator\n",
    "            print(f\"  Processed {i + 1}/{len(gun_files)} gunshot files\")\n",
    "\n",
    "    print(f\"\\nDataset loaded:\")\n",
    "    print(f\"Environment samples: {len(X_env)}\")\n",
    "    print(f\"Gunshot samples: {len(X_gun)}\")\n",
    "    print(f\"Total samples: {len(X_env) + len(X_gun)}\")\n",
    "    \n",
    "    return np.array(X_env), np.array(X_gun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== MAIN ==========\n",
    "print(\"Loading and processing data...\")\n",
    "X_env, X_gun = load_and_extract()\n",
    "\n",
    "print(f\"\\nBalancing dataset:\")\n",
    "print(f\"   Original environment samples: {len(X_env)}\")\n",
    "print(f\"   Original gunshot samples: {len(X_gun)}\")\n",
    "\n",
    "# Balance the dataset - resample environment data to match gunshot data size\n",
    "if len(X_env) != len(X_gun):\n",
    "    if len(X_env) > len(X_gun):\n",
    "        X_env = resample(X_env, n_samples=len(X_gun), random_state=42)\n",
    "        print(f\"   â†³ Resampled environment data to {len(X_gun)} samples\")\n",
    "    else:\n",
    "        X_gun = resample(X_gun, n_samples=len(X_env), random_state=42)\n",
    "        print(f\"   â†³ Resampled gunshot data to {len(X_env)} samples\")\n",
    "\n",
    "# Combine datasets\n",
    "X = np.concatenate((X_env, X_gun))\n",
    "y = np.array([0]*len(X_env) + [1]*len(X_gun))\n",
    "\n",
    "print(f\"\\nFinal balanced dataset:\")\n",
    "print(f\"   Environment samples (class 0): {len(X_env)}\")\n",
    "print(f\"   Gunshot samples (class 1): {len(X_gun)}\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Feature shape per sample: {X_env[0].shape}\")\n",
    "\n",
    "# Add channel dimension for CNN\n",
    "X = np.expand_dims(X, -1)  # shape: (samples, 44, 13, 1)\n",
    "print(f\"   Final input shape: {X.shape}\")\n",
    "print(f\"   Labels shape: {y.shape}\")\n",
    "print(\"Data preparation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7144e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SPLIT ==========\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# ========== MODEL ==========\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(44, 13, 1)),\n",
    "    layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(4, (3, 3), activation='relu'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# ========== TRAIN ==========\n",
    "print(\"Training model...\")\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_split=0.1, verbose=0)\n",
    "\n",
    "# ========== EVALUATE ==========\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Test Loss: {loss*100:.2f}\")\n",
    "\n",
    "# ========== PREDICTIONS FOR CONFUSION MATRIX ==========\n",
    "y_pred_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Accuracy Graph\n",
    "train_acc = history.history['accuracy']  # should have length 10\n",
    "val_acc = history.history['val_accuracy']  # should have length 10\n",
    "plt.figure(figsize=(8, 6))\n",
    "epochs = range(len(train_acc))\n",
    "plt.plot(epochs, train_acc, color='steelblue', label='Train Accuracy', linewidth=2)\n",
    "plt.plot(epochs, val_acc, color='orange', label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Model Accuracy', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(loc='upper left', fontsize=11, frameon=False)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0.62, 1])\n",
    "plt.tight_layout()\n",
    "# Fix the filename formatting\n",
    "filename_suffix = f\"_{NUM_GUNSHOT_FILES}\" if NUM_GUNSHOT_FILES else \"_full\"\n",
    "plt.savefig(f'images/accuracy_plot_{filename_suffix}.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd053670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model Loss Graph  \n",
    "train_loss = history.history['loss']  # This should be a list of floats, one per epoch\n",
    "val_loss = history.history['val_loss']  # Same here\n",
    "plt.figure(figsize=(8, 6))\n",
    "epochs = range(len(train_loss))  # Replace train_loss with your actual loss array\n",
    "plt.plot(epochs, train_loss, color='steelblue', label='Train Loss', linewidth=2)\n",
    "plt.plot(epochs, val_loss, color='orange', label='Validation Loss', linewidth=2)\n",
    "plt.title('Model Loss', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(loc='upper right', fontsize=11, frameon=False)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([min(min(train_loss), min(val_loss)) * 0.9, max(max(train_loss), max(val_loss)) * 1.1])  # Dynamic limit for better zoom\n",
    "plt.tight_layout()\n",
    "# Fix the filename formatting\n",
    "filename_suffix = f\"_{NUM_GUNSHOT_FILES}\" if NUM_GUNSHOT_FILES else \"_full\"\n",
    "plt.savefig(f'images/loss_plot{filename_suffix}.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Environment', 'Gunshot'], \n",
    "            yticklabels=['Environment', 'Gunshot'],\n",
    "            cbar_kws={'label': 'Number of Samples'})\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "# Fix the filename formatting\n",
    "filename_suffix = f\"_{NUM_GUNSHOT_FILES}\" if NUM_GUNSHOT_FILES else \"_full\"\n",
    "plt.savefig(f'images/confusion_matrix{filename_suffix}.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========== DETAILED METRICS ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['Environment', 'Gunshot']))\n",
    "\n",
    "# Calculate additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f\"\\nAdditional Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix Breakdown:\")\n",
    "print(f\"True Positives (Correctly identified gunshots): {tp}\")\n",
    "print(f\"True Negatives (Correctly identified environment sounds): {tn}\")\n",
    "print(f\"False Positives (Environment sounds classified as gunshots): {fp}\")\n",
    "print(f\"False Negatives (Gunshots classified as environment sounds): {fn}\")\n",
    "\n",
    "print(f\"\\nPlots saved:\")\n",
    "print(\"   - accuracy_plot.png & accuracy_plot.pdf\")\n",
    "print(\"   - loss_plot.png & loss_plot.pdf\")\n",
    "print(\"   - confusion_matrix.png & confusion_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== EXPERIMENT TRACKING ==========\n",
    "print(\"\\n\" + \"EXPERIMENT SUMMARY\" + \"=\"*45)\n",
    "print(f\"Dataset Size: {NUM_ENVIRONMENT_FILES if NUM_ENVIRONMENT_FILES else 'ALL'} env + {NUM_GUNSHOT_FILES if NUM_GUNSHOT_FILES else 'ALL'} gunshot files\")\n",
    "print(f\"Total Samples Used: {len(X)}\")\n",
    "print(f\"Test Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Save results to compare different dataset sizes\n",
    "experiment_results = {\n",
    "    'dataset_size': len(X),\n",
    "    'env_files': NUM_ENVIRONMENT_FILES if NUM_ENVIRONMENT_FILES else 'ALL',\n",
    "    'gun_files': NUM_GUNSHOT_FILES if NUM_GUNSHOT_FILES else 'ALL',\n",
    "    'test_accuracy': acc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1_score,\n",
    "    'true_positives': tp,\n",
    "    'true_negatives': tn,\n",
    "    'false_positives': fp,\n",
    "    'false_negatives': fn\n",
    "}\n",
    "\n",
    "print(f\"\\nCopy this result for comparison:\")\n",
    "print(f\"Dataset: {experiment_results['env_files']}/{experiment_results['gun_files']} | Acc: {acc:.3f} | F1: {f1_score:.3f} | Precision: {precision:.3f} | Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== DATA EXPORT ==========\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_data():\n",
    "    \"\"\"Export all study data to meet journal requirements\"\"\"\n",
    "    \n",
    "    # Create export directory\n",
    "    export_dir = \"data_export\"\n",
    "    if not os.path.exists(export_dir):\n",
    "        os.makedirs(export_dir)\n",
    "        os.makedirs(f\"{export_dir}/metrics\")\n",
    "        os.makedirs(f\"{export_dir}/figures_data\")\n",
    "        os.makedirs(f\"{export_dir}/raw_data\")\n",
    "    \n",
    "    print(\"Exporting data for journal requirements...\")\n",
    "    \n",
    "    # 1. Export training history (epoch-by-epoch values)\n",
    "    training_history_df = pd.DataFrame({\n",
    "        'epoch': range(0, len(train_acc)),\n",
    "        'training_accuracy': train_acc,\n",
    "        'validation_accuracy': val_acc,\n",
    "        'training_loss': train_loss,\n",
    "        'validation_loss': val_loss\n",
    "    })\n",
    "    training_history_df.to_csv(f\"{export_dir}/metrics/training_history_per_epoch_{filename_suffix}.csv\", index=False)\n",
    "    \n",
    "    # 2. Export figure data points (exact values used in graphs)\n",
    "    # Accuracy plot data\n",
    "    accuracy_plot_data = pd.DataFrame({\n",
    "        'epoch': range(0, len(train_acc)),\n",
    "        'training_accuracy': train_acc,\n",
    "        'validation_accuracy': val_acc\n",
    "    })\n",
    "    accuracy_plot_data.to_csv(f\"{export_dir}/figures_data/accuracy_plot_data_{filename_suffix}.csv\", index=False)\n",
    "    \n",
    "    # Loss plot data  \n",
    "    loss_plot_data = pd.DataFrame({\n",
    "        'epoch': range(0, len(train_loss)),\n",
    "        'training_loss': train_loss,\n",
    "        'validation_loss': val_loss\n",
    "    })\n",
    "    loss_plot_data.to_csv(f\"{export_dir}/figures_data/loss_plot_data_{filename_suffix}.csv\", index=False)\n",
    "    \n",
    "    # Confusion matrix data\n",
    "    confusion_matrix_data = pd.DataFrame(cm, \n",
    "                                       index=['True_Environment', 'True_Gunshot'],\n",
    "                                       columns=['Predicted_Environment', 'Predicted_Gunshot'])\n",
    "    confusion_matrix_data.to_csv(f\"{export_dir}/figures_data/confusion_matrix_data_{filename_suffix}.csv\")\n",
    "    \n",
    "    # 4. Export detailed metrics and statistics\n",
    "    detailed_metrics = {\n",
    "        'export_timestamp': datetime.now().isoformat(),\n",
    "        'dataset_info': {\n",
    "            'total_samples': len(X),\n",
    "            'environment_samples': NUM_ENVIRONMENT_FILES if NUM_ENVIRONMENT_FILES else 'ALL',\n",
    "            'gunshot_samples': NUM_GUNSHOT_FILES if NUM_GUNSHOT_FILES else 'ALL',\n",
    "            'test_samples': len(y_test),\n",
    "            'feature_shape': list(X[0].shape)\n",
    "        },\n",
    "        'model_performance': {\n",
    "            'test_accuracy': float(acc),\n",
    "            'test_loss': float(loss),\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'f1_score': float(f1_score),\n",
    "            'specificity': float(specificity)\n",
    "        },\n",
    "        'confusion_matrix_breakdown': {\n",
    "            'true_positives': int(tp),\n",
    "            'true_negatives': int(tn),\n",
    "            'false_positives': int(fp),\n",
    "            'false_negatives': int(fn)\n",
    "        },\n",
    "        'training_parameters': {\n",
    "            'epochs': 10,\n",
    "            'batch_size': 8,\n",
    "            'validation_split': 0.1,\n",
    "            'optimizer': 'adam',\n",
    "            'loss_function': 'binary_crossentropy',\n",
    "            'random_state': 42\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(f\"{export_dir}/metrics/complete_study_metrics_{filename_suffix}.json\", 'w') as f:\n",
    "        json.dump(detailed_metrics, f, indent=2)\n",
    "    \n",
    "    # 5. Export means, standard deviations, and statistical measures\n",
    "    statistical_summary = pd.DataFrame({\n",
    "        'Metric': ['Training Accuracy', 'Validation Accuracy', 'Training Loss', 'Validation Loss'],\n",
    "        'Mean': [np.mean(train_acc), np.mean(val_acc), np.mean(train_loss), np.mean(val_loss)],\n",
    "        'Std_Deviation': [np.std(train_acc), np.std(val_acc), np.std(train_loss), np.std(val_loss)],\n",
    "        'Min_Value': [np.min(train_acc), np.min(val_acc), np.min(train_loss), np.min(val_loss)],\n",
    "        'Max_Value': [np.max(train_acc), np.max(val_acc), np.max(train_loss), np.max(val_loss)],\n",
    "        'Final_Value': [train_acc[-1], val_acc[-1], train_loss[-1], val_loss[-1]]\n",
    "    })\n",
    "    statistical_summary.to_csv(f\"{export_dir}/metrics/statistical_summary_{filename_suffix}.csv\", index=False)\n",
    "    \n",
    "    print(f\"All data exported to: {export_dir}/\")\n",
    "    print(f\"Files created:\")\n",
    "    for root, dirs, files in os.walk(export_dir):\n",
    "        for file in files:\n",
    "            rel_path = os.path.relpath(os.path.join(root, file), export_dir)\n",
    "            print(f\"   - {rel_path}\")\n",
    "    \n",
    "    return export_dir\n",
    "\n",
    "# Import pandas for data export\n",
    "import pandas as pd\n",
    "\n",
    "# Run the export\n",
    "export_directory = export_data()\n",
    "print(f\"\\ndata export completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== MODEL EXPORT ==========\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Quick model export function\n",
    "def quick_export_model():\n",
    "    \"\"\"Export model in key formats for deployment\"\"\"\n",
    "    \n",
    "    # Create export directory\n",
    "    models_dir = \"exported_models\"\n",
    "    os.makedirs(f\"{models_dir}/keras\", exist_ok=True)\n",
    "    model_name = f\"gunshot_detection\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"ðŸš€ Exporting model formats...\")\n",
    "    \n",
    "    # Keras native format\n",
    "    try:\n",
    "        keras_path = f\"{models_dir}/keras/{model_name}.keras\" \n",
    "        model.save(keras_path)\n",
    "        results['keras'] = keras_path\n",
    "        print(f\" Keras format: {keras_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Keras failed: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Export models\n",
    "print(\"Starting model export...\")\n",
    "export_results = quick_export_model()\n",
    "\n",
    "print(f\"\\nExport completed! Available formats:\")\n",
    "for format_name, path in export_results.items():\n",
    "    if isinstance(path, str) and not any(x in format_name for x in ['size', 'percent']):\n",
    "        print(f\" {format_name.upper()}: {os.path.basename(path)}\")\n",
    "\n",
    "# Show file sizes\n",
    "if 'tflite_size_kb' in export_results:\n",
    "    print(f\"\\nModel sizes:\")\n",
    "    print(f\"   TensorFlow Lite: {export_results['tflite_size_kb']:.1f} KB\")\n",
    "    if 'quantized_size_kb' in export_results:\n",
    "        print(f\"   Quantized TFLite: {export_results['quantized_size_kb']:.1f} KB\") \n",
    "        print(f\"   Space saved: {export_results['compression_percent']:.1f}%\")\n",
    "\n",
    "print(f\"\\nAll files saved in: exported_models/\")\n",
    "print(\"\\nModel export and quantization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FULL INT8 QUANTIZATION FOR MICROCONTROLLERS ==========\n",
    "# Create fully quantized INT8 model for RP2040 and other microcontrollers\n",
    "\n",
    "def representative_dataset():\n",
    "    \"\"\"Representative dataset for calibrating quantization\"\"\"\n",
    "    for i in range(100):\n",
    "        yield [X_train[i:i+1].astype(np.float32)]\n",
    "\n",
    "print(\"Converting to fully quantized INT8 TFLite model...\")\n",
    "print(\"This model will be optimized for microcontrollers like RP2040\")\n",
    "\n",
    "try:\n",
    "    # Create converter with full integer quantization\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  \n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    # Convert the model\n",
    "    tflite_model_int8 = converter.convert()\n",
    "    \n",
    "    # Save the quantized model\n",
    "    models_dir = \"exported_models\"\n",
    "    os.makedirs(f\"{models_dir}/quantized\", exist_ok=True)\n",
    "    quantized_filename = \"exported_models/quantized/gunshot_model_quant.tflite\"\n",
    "    with open(quantized_filename, \"wb\") as f:\n",
    "        f.write(tflite_model_int8)\n",
    "    \n",
    "    # Get file size info\n",
    "    int8_size_kb = len(tflite_model_int8) / 1024\n",
    "    \n",
    "    print(f\"\\nSaved: {quantized_filename}\")\n",
    "    print(f\"INT8 Model size: {int8_size_kb:.1f} KB\")\n",
    "\n",
    "    print(f\"\\nTo convert to C header file for RP2040:\")\n",
    "    print(f\"   xxd -i {quantized_filename} > gunshot_model_quant.h\")\n",
    "\n",
    "    print(f\"\\nMicrocontroller deployment notes:\")\n",
    "    print(f\"   - Input/Output: INT8 format (quantized)\")\n",
    "    print(f\"   - Input shape: [1, 44, 13, 1]\")\n",
    "    print(f\"   - Memory requirement: ~{int8_size_kb:.1f} KB for model\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"INT8 quantization failed: {e}\")\n",
    "    print(\"This might happen if the model is not suitable for full integer quantization\")\n",
    "\n",
    "print(\"\\nFull INT8 quantization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a52da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
